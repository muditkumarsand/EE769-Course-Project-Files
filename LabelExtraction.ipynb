{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabelExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk7ku4b-woNv"
      },
      "source": [
        "This program extract features from most of the product pages mentioned below in the codes and we can add more ecommerce websites just with small modification in the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ty6AxHDrNVb"
      },
      "source": [
        "Dependencies Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y45Uc6TsrQaC",
        "outputId": "6730ebda-eefc-4c51-fbd0-764f998520ab"
      },
      "source": [
        "!pip install requests.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting requests.html\n",
            "  Using cached https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.7/dist-packages (from requests.html) (1.4.3)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.7/dist-packages (from requests.html) (1.22.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from requests.html) (0.1.11)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests.html) (0.0.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from requests.html) (0.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests.html) (2.23.0)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.7/dist-packages (from requests.html) (1.19.0)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests.html) (4.2.6)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests.html) (1.1.0)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from w3lib->requests.html) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests.html) (4.6.3)\n",
            "Requirement already satisfied: importlib-metadata<3.0.0,>=2.1.1; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests.html) (2.1.1)\n",
            "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests.html) (8.1.0)\n",
            "Requirement already satisfied: websockets<9.0,>=8.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests.html) (8.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests.html) (1.25.11)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests.html) (4.60.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests.html) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests.html) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests.html) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->requests.html) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<3.0.0,>=2.1.1; python_version < \"3.8\"->pyppeteer>=0.0.14->requests.html) (3.4.1)\n",
            "Installing collected packages: requests.html\n",
            "Successfully installed requests.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiEktg36rZpp"
      },
      "source": [
        "Module Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3KX1M22rcAi"
      },
      "source": [
        "import nest_asyncio\n",
        "from requests_html import AsyncHTMLSession\n",
        "import json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyzttBto8VBP"
      },
      "source": [
        "Tackle the event loop issue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JVSc0Kv8dqd"
      },
      "source": [
        "nest_asyncio.apply()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dedykkDruNJ"
      },
      "source": [
        "Taking the Url from user from which We need to extract information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tqCnIs0r19k",
        "outputId": "2736ca01-f578-48d9-e35f-337ad3f5f8de"
      },
      "source": [
        "print(\"Please Make a website choice by pressing the key assigned:\")\n",
        "print(\"1:   Amazon India\")\n",
        "print(\"2:   Nurserylive\")\n",
        "print(\"3:   Flipkart\")\n",
        "choice = 3 #int(input())\n",
        "url = input()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please Make a website choice by pressing the key assigned:\n",
            "1:   Amazon India\n",
            "2:   Nurserylive\n",
            "3:   Flipkart\n",
            "https://www.flipkart.com/divano-leatherette-office-arm-chair/p/itmf3zshpr5znzew?pid=OSCEGNYUHEUE2CTE&lid=LSTOSCEGNYUHEUE2CTEML2YFU&marketplace=FLIPKART&store=wwe%2Fy7b%2Ffoc&srno=b_1_40&otracker=hp_omu_Furniture%2BBestsellers_4_9.dealCard.OMU_C7XV4DRK9HQQ_7&otracker1=hp_omu_WHITELISTED_neon%2Fmerchandising_Furniture%2BBestsellers_NA_dealCard_cc_4_NA_view-all_7&fm=neon%2Fmerchandising&iid=af0ca14a-e454-4c4e-9bf3-bcf06360b49d.OSCEGNYUHEUE2CTE.SEARCH&ppt=browse&ppn=browse&ssid=ulqa7gq81s0000001621339151317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb95lGDL8gOY"
      },
      "source": [
        "Function to extract the feature from url"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_LNK4Fk8lCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30281cc1-eaba-4a7e-985f-8528a93a26d3"
      },
      "source": [
        "session = AsyncHTMLSession()\n",
        "async def getInfoamazon():    \n",
        "    getvalues = await session.get(url)    \n",
        "    try:\n",
        "        product = {\n",
        "            'title': getvalues.html.xpath('//*[@id=\"productTitle\"]', first=True).text,\n",
        "            'price': getvalues.html.xpath('//*[@id=\"priceblock_ourprice\"]', first=True).text,\n",
        "            'brand' : getvalues.html.xpath('//*[@id=\"bylineInfo\"]', first=True).text\n",
        "        }\n",
        "        print(product)\n",
        "    except:\n",
        "      try:\n",
        "        product = {\n",
        "            'title': getvalues.html.xpath('//*[@id=\"productTitle\"]', first=True).text,\n",
        "            'price': getvalues.html.xpath('//*[@id=\"priceblock_ourprice\"]', first=True).text,\n",
        "        }\n",
        "        print(product)\n",
        "      except:\n",
        "        product = {\n",
        "            'title': '',\n",
        "            'price': '',\n",
        "            'brand' : ''\n",
        "        }\n",
        "        print(product)\n",
        "    return product\n",
        "#code for flipkart\n",
        "async def getInfoflipkart():    \n",
        "    getvalues = await session.get(url)    \n",
        "    try:\n",
        "      product = {\n",
        "            'title': getvalues.html.xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/h1/span[2]', first=True).text,\n",
        "            'price': getvalues.html.xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[1]/div/div[1]', first=True).text,\n",
        "            'brand': getvalues.html.xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/h1/span[1]', first=True).text\n",
        "        }\n",
        "      print(product)\n",
        "    except:\n",
        "      try:\n",
        "        product = {\n",
        "            'title': getvalues.html.xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/h1/span', first=True).text,\n",
        "            'price': getvalues.html.xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div[1]/div/div[1]', first=True).text\n",
        "        }\n",
        "        print(product)       \n",
        "        \n",
        "      except:\n",
        "        try:\n",
        "          product = {\n",
        "            'title': getvalues.html.xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/h1/span', first=True).text,\n",
        "            'price': getvalues.html.xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[4]/div[1]/div/div[1]', first=True).text\n",
        "        }\n",
        "          print(product)\n",
        "        except:\n",
        "          product = {\n",
        "            'title': '',\n",
        "            'price': ''\n",
        "        }\n",
        "          print(product)\n",
        "    return product\n",
        "\n",
        "#Code for nursery live\n",
        "async def getInfonurserylive():\n",
        "    \n",
        "    getvalues = await session.get(url)\n",
        "    \n",
        "    try:\n",
        "      product = {\n",
        "            'title': getvalues.html.xpath('//*[@id=\"shopify-section-static-product\"]/section/article/div[2]/div[1]/h1', first=True).text,\n",
        "            'price': getvalues.html.xpath('//*[@id=\"shopify-section-static-product\"]/section/article/div[2]/div[1]/div[2]/div/div[2]/span[2]', first=True).text\n",
        "        }\n",
        "      print(product)\n",
        "    except:\n",
        "      try:\n",
        "        product = {\n",
        "            'title': getvalues.html.xpath('//*[@id=\"shopify-section-static-product\"]/section/article/div[2]/div[1]/h1', first=True).text,\n",
        "            'price': getvalues.html.xpath('//*[@id=\"shopify-section-static-product\"]/section/article/div[2]/div[1]/div[2]/div/div[2]/span', first=True).text\n",
        "        }\n",
        "        print(product)       \n",
        "        \n",
        "      except:\n",
        "        product = {\n",
        "            'title': '',\n",
        "            'price': ''\n",
        "        }\n",
        "        print(product)\n",
        "    return product\n",
        "\n",
        "if choice == 1:\n",
        "  result = session.run(getInfoamazon)\n",
        "  \n",
        "elif choice == 2:\n",
        "  result = session.run(getInfonurserylive);\n",
        "elif choice == 3:\n",
        "  result = session.run(getInfoflipkart)\n",
        "    \n",
        "result[0].update({\"Website\" : url})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'title': 'DIVANO Leatherette Office Arm Chair\\xa0\\xa0(Brown)', 'price': '₹6,999'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5Pg0oMAZDGK"
      },
      "source": [
        "Updating json file of the data extracted... Provide the path of the file below, I am using filepath of my drive, for different user it may be different.\n",
        "\n",
        "**Please run the below cell once for one product otherwise it will update the same product twice.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zSPz6XxZdtt"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/label_Extraction.json', 'a', encoding='utf-8') as output:\n",
        "    json.dump(result, output, ensure_ascii=False, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSq7ntsOS9s1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a359b7a3-0d99-4713-8e67-e3af95651c31"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iK1YQOUTCaQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}